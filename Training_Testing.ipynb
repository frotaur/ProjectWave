{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from Trainer import Trainer\n",
    "\n",
    "from WaveDataset import WaveDataset\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 237648 examples\n",
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "from Trainer import Trainer\n",
    "from WaveModel import WaveModel\n",
    "# block_size = 512\n",
    "\n",
    "mydataset = WaveDataset('2sources_30plusmics_240k',max_length=512,max_mics=10)\n",
    "# automatically take correct number of mic for model\n",
    "max_length,mic_num,source_num = mydataset.get_config()\n",
    "\n",
    "model = WaveModel(mic_num=mic_num,source_num=source_num,\n",
    "tot_timesteps=max_length,\n",
    "n_embd=160,n_hidden=512,\n",
    "n_head=8,n_layer=8,dropout=0.1)\n",
    "device = 'cuda'\n",
    "m=model.to(device)\n",
    "train=Trainer(model,mydataset,run_name = '240k_2source_10mics_160embd_512hidden_8head_8layer',\n",
    "              batch_size=128,device=device)\n",
    "train.to(device)\n",
    "\n",
    "print('device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.model.train()\n",
    "train.optimization(epochs=200,eval_interval=2,lr=1e-3,loadingbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'SaveWeights/240k_2source_10mics_160embd_512hidden_8head_8layer_no masking.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# For loading weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39mSaveWeights/240k_2source_10mics_160embd_512hidden_8head_8layer_no masking.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/training_time/Trainer.py:50\u001b[0m, in \u001b[0;36mTrainer.load_weights\u001b[0;34m(self, weights_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_weights\u001b[39m(\u001b[39mself\u001b[39m,weights_path):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(weights_path))\n\u001b[1;32m     51\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoad successful\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/training_time/.venv/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/training_time/.venv/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/training_time/.venv/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'SaveWeights/240k_2source_10mics_160embd_512hidden_8head_8layer_no masking.pt'"
     ]
    }
   ],
   "source": [
    "# For loading weights\n",
    "train.load_weights('SaveWeights/240k_2source_10mics_160embd_512hidden_8head_8layer_no masking.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize microphone recordings.\n",
    "num=3\n",
    "recordings = mydataset[num][0] # (3,M,T)\n",
    "print(recordings.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(3):\n",
    "    mic_recording = recordings[0,i,:].numpy()\n",
    "\n",
    "    x = range(len(mic_recording))\n",
    "    ax.plot(x, mic_recording)\n",
    "ax.set(xlabel='time (s)', ylabel='Values', title='Observations at 3 micphones')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.scatter(recordings[1,:,0],recordings[2,:,0])\n",
    "plt.xlim([0, 1])  # setting x limit\n",
    "plt.ylim([0, 1])  # setting y limit\n",
    "\n",
    "ax.set(xlabel='x', ylabel='y', title='Scatterplot of micphones')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
