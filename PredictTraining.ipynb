{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 10 examples\n",
      "device :  cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from Trainer import Trainer\n",
    "\n",
    "from WaveValueDataset import WaveValueDataset\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from Trainer import SequenceTrainer\n",
    "from WaveModel import PredictionModel\n",
    "# block_size = 512\n",
    "\n",
    "mydataset = WaveValueDataset('full',161)\n",
    "# M,N,n_embd,n_hidden,n_head,n_layer,dropout=0.2\n",
    "model = PredictionModel(mic_num=6,tot_timesteps=160,n_embd=80,n_hidden=120,n_head=8,n_layer=4,dropout=0.2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "m=model.to(device)\n",
    "train=SequenceTrainer(model,mydataset,eval_iters=5,batch_size=2,device=device)\n",
    "train.to('cpu')\n",
    "\n",
    "print('device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gonna return : torch.Size([3, 6, 161])\n",
      "Gonna return : torch.Size([3, 6, 161])\n",
      "Idx shape : torch.Size([2, 3, 6, 160])\n",
      "Idx shape : torch.Size([2, 160, 80])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 2\u001b[0m train\u001b[39m.\u001b[39;49moptimization(epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,eval_interval\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,loadingbar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/ZilanNew/ProjectWave/Trainer.py:75\u001b[0m, in \u001b[0;36mTrainer.optimization\u001b[0;34m(self, epochs, eval_interval, lr, loadingbar)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m epoch \u001b[39m==\u001b[39m epochs \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_loss()\n\u001b[1;32m     76\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m==\u001b[39m epochs\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/PythonEnv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ZilanNew/ProjectWave/Trainer.py:53\u001b[0m, in \u001b[0;36mTrainer.estimate_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m     52\u001b[0m         X[i]\u001b[39m=\u001b[39mX[i]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 53\u001b[0m     predicts, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X[\u001b[39m1\u001b[39;49m],X[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     54\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     56\u001b[0m out[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(losses)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/PythonEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ZilanNew/ProjectWave/WaveModel.py:143\u001b[0m, in \u001b[0;36mPredictionModel.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    x = (B,3,M,T)\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m    target = (B,3,M,T) translated by one\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m x\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfo(x) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransfo(x) \u001b[39m# (B,T,M)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m(target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    146\u001b[0m     \u001b[39m# Mse loss between prediction and target\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(x,target\u001b[39m.\u001b[39mpermute((\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/PythonEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/ZilanNew/ProjectWave/WaveModel.py:114\u001b[0m, in \u001b[0;36mNoHeadModel.forward\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    params : \u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m    idx : mic recordings, (B,3,M,T). Chan 0 : recorded value, chan 1,2 : position\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIdx shape : \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m B,_,M,T \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mshape \u001b[39m#(B,3,M,T)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m idx\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpermute(idx,(\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m)) \u001b[39m# (B,T,M,3)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m idx\u001b[39m=\u001b[39midx\u001b[39m.\u001b[39mreshape(B,T,M\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "train.model.train()\n",
    "train.optimization(epochs=10,eval_interval=2,lr=1e-3,loadingbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
