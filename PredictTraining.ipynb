{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 10000 examples\n",
      "Initialized dataset with 20000 examples\n",
      "Initalized model with 3.54 M params\n",
      "device :  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from Trainer import Trainer\n",
    "\n",
    "from WaveValueDataset import WaveValueDataset\n",
    "from WaveDataset import WaveDataset\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from Trainer import SequenceTrainer\n",
    "from WaveModel import PredictionModel, SourcePredictModel, WaveModel\n",
    "train_length = 256\n",
    "\n",
    "valuedataset = WaveValueDataset('10k_1orig',train_length+1)\n",
    "wavedataset = WaveDataset('3sources',train_length)\n",
    "# M,N,n_embd,n_hidden,n_head,n_layer,dropout=0.2\n",
    "model = PredictionModel(mic_num=6,tot_timesteps=train_length,n_embd=240,n_hidden=240*3,n_head=8,n_layer=6,dropout=0.1)\n",
    "wavemodel = WaveModel(mic_num=15,source_num=3,tot_timesteps=train_length,n_embd=240,n_hidden=240*3,n_head=8,n_layer=6,dropout=0.1)\n",
    "\n",
    "model.load_state_dict(torch.load('SavePretrained.pt'))\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "m=model.to(device)\n",
    "train=SequenceTrainer(model,valuedataset,batch_size=128,device=device)\n",
    "trainwave = Trainer(wavemodel,wavedataset,batch_size=128,device=device)\n",
    "train.to(device)\n",
    "trainwave.to(device)\n",
    "print(f'Initalized model with {sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6:.2f} M params')\n",
    "print('device : ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'SavePretrained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32768x15 and 6x240)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainwave\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 2\u001b[0m trainwave\u001b[39m.\u001b[39;49moptimization(epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,eval_interval\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n",
      "File \u001b[0;32m~/ZilanNew/Trainer.py:74\u001b[0m, in \u001b[0;36mTrainer.optimization\u001b[0;34m(self, epochs, eval_interval, lr, loadingbar)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m eval_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m epoch \u001b[39m==\u001b[39m epochs \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_loss()\n\u001b[1;32m     75\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val loss \u001b[39m\u001b[39m{\u001b[39;00mlosses[\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m==\u001b[39m epochs\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/ZilanNew/Trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.estimate_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m     data\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     51\u001b[0m     target\u001b[39m=\u001b[39mtarget\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 52\u001b[0m     predicts, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(data,target)\n\u001b[1;32m     53\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     55\u001b[0m out[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(losses)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ZilanNew/WaveModel.py:80\u001b[0m, in \u001b[0;36mWaveModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m# idx=torch.reshape(idx,(B,T*M*3))\u001b[39;00m\n\u001b[1;32m     78\u001b[0m pos_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_table(torch\u001b[39m.\u001b[39marange(T, device\u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mdevice)[\u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mexpand(B,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m idx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mval_embed(vals)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embed(pos)[:,\u001b[39mNone\u001b[39;00m,:]\u001b[39m+\u001b[39mpos_emb \u001b[39m# (B,T,n_embed)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks(idx) \u001b[39m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_f(idx) \u001b[39m# (B,T,C) \u001b[39;00m\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32768x15 and 6x240)"
     ]
    }
   ],
   "source": [
    "trainwave.model.train()\n",
    "trainwave.optimization(epochs=100,eval_interval=3,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 0.0988, val loss 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5: train loss 0.0880, val loss 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10: train loss 0.0970, val loss 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n",
      "100%|██████████| 71/71 [00:13<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15: train loss 0.0851, val loss 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:13<00:00,  5.39it/s]\n",
      "  6%|▌         | 4/71 [00:00<00:15,  4.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 2\u001b[0m train\u001b[39m.\u001b[39;49moptimization(epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,eval_interval\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,loadingbar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/ZilanNew/Trainer.py:166\u001b[0m, in \u001b[0;36mSequenceTrainer.optimization\u001b[0;34m(self, epochs, eval_interval, lr, loadingbar)\u001b[0m\n\u001b[1;32m    163\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    165\u001b[0m predicts, loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(data,target)\n\u001b[0;32m--> 166\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/penv/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.model.train()\n",
    "train.optimization(epochs=200,eval_interval=5,lr=1e-3,loadingbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 0.6269, val loss 0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:04<00:00, 32.09it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.06it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.05it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: train loss 0.0837, val loss 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:04<00:00, 32.08it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.07it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.05it/s]\n",
      "100%|██████████| 141/141 [00:04<00:00, 32.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8: train loss 0.0834, val loss 0.0873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:04<00:00, 32.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use trained model to initialize in source-predict\n",
    "predictor = SourcePredictModel(train.model.get_trained_transfo(),n_sources=1,n_hidden=32).to(device)\n",
    "predictor.freeze_body(True)\n",
    "pred_trainer = Trainer(predictor,wavedataset,batch_size=64,device='cuda:0')\n",
    "pred_trainer.optimization(9,eval_interval=4,lr=5e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 0.0342, val loss 0.0367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.36it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.35it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4: train loss 0.0215, val loss 0.0368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.30it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.31it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8: train loss 0.0171, val loss 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.35it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.33it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12: train loss 0.0150, val loss 0.0401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.34it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16: train loss 0.0123, val loss 0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.35it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.28it/s]\n",
      "100%|██████████| 141/141 [00:13<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19: train loss 0.0103, val loss 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:13<00:00, 10.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predictor.freeze_body(False)\n",
    "pred_trainer = Trainer(predictor,wavedataset,batch_size=64,device='cuda:0')\n",
    "pred_trainer.optimization(20,eval_interval=4,lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
